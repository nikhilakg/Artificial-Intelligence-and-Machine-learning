{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f9fe0a",
   "metadata": {},
   "source": [
    "• **DOMAIN**: Smartphone, Electronics\n",
    "\n",
    "• **CONTEXT**: India is the second largest market globally for smartphones after China. About 134 million smartphones were sold across India in the year 2017 and is estimated to increase to about 442 million in 2022. India ranked second in the average time spent on mobile web by smartphone users across Asia Pacific. The combination of very high sales volumes and the average smartphone consumer behaviour has made India a very attractive market for foreign vendors. As per Consumer behaviour, 97% of consumers turn to a search engine when they are buying a product vs. 15% who turn to social media. If a seller succeeds to publish smartphones based on user’s behaviour/choice at the right place, there are 90% chances that user will enquire for the same. This Case Study is targeted to build a recommendation system based on individual consumer’s behaviour or choice.\n",
    "\n",
    "• **DATA DESCRIPTION**:\n",
    "- **author** : name of the person who gave the rating\n",
    "- **country** : country the person who gave the rating belongs to\n",
    "- **data** : date of the rating\n",
    "- **domain**: website from which the rating was taken from\n",
    "- **extract**: rating content\n",
    "- **language**: language in which the rating was given\n",
    "- **product**: name of the product/mobile phone for which the rating was given\n",
    "- **score**: average rating for the phone\n",
    "- **score_max**: highest rating given for the phone\n",
    "- **source**: source from where the rating was taken\n",
    "\n",
    "• **PROJECT OBJECTIVE**: We will build a recommendation system using popularity based and collaborative filtering methods to recommend mobile phones to a user which are most popular and personalised respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5c530",
   "metadata": {},
   "source": [
    "### Steps and tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa0f10",
   "metadata": {},
   "source": [
    "### 1. Import the necessary libraries and read the provided CSVs as a data frame and perform the below steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from surprise import SVD\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_1.csv')\n",
    "data2 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_2.csv')\n",
    "data3 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_3.csv')\n",
    "data4 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_4.csv')\n",
    "data5 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_5.csv')\n",
    "data6 = pd.read_csv('D:/Nikhila/PGP - AIML/2. Projects/6. Recommendation Systems/phone_user_review_file_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc2ce6",
   "metadata": {},
   "source": [
    "#### A. Merge all the provided CSVs into one dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7729a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the data1', data1.shape)\n",
    "print('Shape of the data2', data2.shape)\n",
    "print('Shape of the data3', data3.shape)\n",
    "print('Shape of the data4', data4.shape)\n",
    "print('Shape of the data5', data5.shape)\n",
    "print('Shape of the data6', data6.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Total rows: {data1.shape[0]+data2.shape[0]+data3.shape[0]+data4.shape[0]+data5.shape[0]+data6.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7c1b0",
   "metadata": {},
   "source": [
    "#### Check whether the column names are same in all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(np.unique(data1.columns.tolist()) == np.unique(data1.columns.tolist()+data2.columns.tolist()+data3.columns.tolist()+\n",
    "                                                   data4.columns.tolist()+data5.columns.tolist()+data6.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a00169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2,data3,data4,data5,data6], ignore_index=True)\n",
    "\n",
    "print('Shape of the dataframe', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ebe51",
   "metadata": {},
   "source": [
    "#### B. Explore, understand the Data and share at least 2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69239269",
   "metadata": {},
   "source": [
    "**Observation** -\n",
    "- 1) We see that the count of rows is less for - \"score\", \"score_max\", \"extract\", \"author\" and \"product\" - **Indicating missing values**.\n",
    "- 2) \"score\" and \"score_max\" are **stored as float** and other features are of object type.\n",
    "- 3) \"date\" should be of **datetype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4141c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['score_max'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f4fdb",
   "metadata": {},
   "source": [
    "**Observation** -\n",
    "- 4) \"score_max\" value for all the observation is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a3dc1",
   "metadata": {},
   "source": [
    "#### We will see the distribution of \"product\" and \"author\" since we will be dealing with it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d403c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = data['product'].value_counts()[:10]\n",
    "print('Distribution of number of products: \\n',product)\n",
    "sns.barplot(y=product.index,x=product)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['author'].value_counts(dropna=False)[:10]\n",
    "print('Distribution of number of author: \\n',users)\n",
    "users.index = users.index.map(str)\n",
    "sns.barplot(y=users.index,x=users)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4775c7f",
   "metadata": {},
   "source": [
    "**Observation** - \n",
    "- 5) We have \"nan\" values\n",
    "- 6) We see authors like - 'Anonymous' and 'unknown'.\n",
    "- 7) authors like \"Amazon customer\", \"Cliente Amazon\", \"Client d'Amazon\" are all the same in different languages.\n",
    "\n",
    "We will remove in next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3a777",
   "metadata": {},
   "source": [
    "#### C. Round off scores to the nearest integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'] = data['score'].round(0).astype('Int64')\n",
    "print(list(data.score.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ace4a",
   "metadata": {},
   "source": [
    "**Observation** - We see 0 and <NA> values here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5fc62",
   "metadata": {},
   "source": [
    "#### D. Check for missing values. Impute the missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff0117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_val=data.isna().sum().round(2)\n",
    "missing_val1 = (missing_val*100/data.shape[0]).round(2)\n",
    "print('Missing count and percentages for each column are: \\n',missing_val.astype('str') +' ('+ missing_val1.astype('str')+'%)')\n",
    "\n",
    "del missing_val, missing_val1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5c8c1",
   "metadata": {},
   "source": [
    "**'score'** and **'score_max'** have exactly same number of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aace31",
   "metadata": {},
   "source": [
    "a) Impute the **\"score\"** column with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'] = data['score'].fillna(data['score'].median())\n",
    "\n",
    "print('Shape of the dataframe after imputing \"score\" with median', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbead66",
   "metadata": {},
   "source": [
    "b) We will not change **\"score_max\"** column values since it has unique value of 10 and it is irrelevant feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e69bb0",
   "metadata": {},
   "source": [
    "c) **\"extract\"**,  **\"author\"** and **\"product\"** - We will remove all null values and \"Anonymous\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbc709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove null values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#To remove \"Anonymous\" and \"unknown\"\n",
    "unknowns = ['Anonymous','unknown','Anonymous ']\n",
    "data['author'].replace(to_replace = unknowns, value = 'Anonymous', inplace=True)\n",
    "data = data[data[\"author\"] != 'Anonymous']\n",
    "\n",
    "print('Shape of the dataframe after removing null values and \"Anonymous\" values', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37366ea",
   "metadata": {},
   "source": [
    "#### E. Check for duplicate values and remove them, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb813624",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = data[data.duplicated()]\n",
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "print('Shape of the dataframe after removing duplicate values', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c2dcf",
   "metadata": {},
   "source": [
    "#### F. Keep only 1 Million data samples. Use random state=612."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=1000000, random_state=612)\n",
    "\n",
    "print('Shape of the dataframe after keeping only 1 Million data samples', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34a1f1",
   "metadata": {},
   "source": [
    "#### G. Drop irrelevant features. Keep features like Author, Product, and Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d12b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['phone_url','date','lang','country','source','domain','score_max','extract'], axis = 1, inplace = True)\n",
    "\n",
    "print('Shape of the dataframe after dropping irrelevant features', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91b6cf",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f3228",
   "metadata": {},
   "source": [
    "### 2. Answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30998532",
   "metadata": {},
   "source": [
    "#### A. Identify the most rated products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254283a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product which has received most number of ratings - \"count\"\n",
    "data.groupby('product')['score'].count().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e76edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product which has highest mean score - \"mean\"\n",
    "data.groupby('product')['score'].mean().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product with its \"mean score\" and \"count of score\"\n",
    "product_mean_count = pd.DataFrame(data.groupby('product')['score'].mean())\n",
    "product_mean_count['score_counts'] = pd.DataFrame(data.groupby('product')['score'].count()) \n",
    "product_mean_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c93bb5",
   "metadata": {},
   "source": [
    "**Observation** - Although some of the products have score as 10, the score_count of the product is 1 hence the mean of score will be 10, which is less significant. we will explore more in section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe2fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "product_mean_count['score'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb9ac8",
   "metadata": {},
   "source": [
    "**Observation** - \n",
    "- We can see that the integer values have taller bars than the floating values.\n",
    "- Furthermore, it is evident that the data has a weak normal distribution. \n",
    "\n",
    "- Products with a higher number of ratings usually have a high average rating as well since a good product is normally well-known, and thus usually has a higher rating. Let's see if this is also the case with the products in our dataset. We will plot average ratings against the number of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "sns.jointplot(x='score', y='score_counts', data=product_mean_count, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcdf77a",
   "metadata": {},
   "source": [
    "**Observation** - The graph shows that, in general, products with higher average ratings actually have more number of ratings, compared with products that have lower average ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c00ef9",
   "metadata": {},
   "source": [
    "#### B. Identify the users with most number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author which has received most number of ratings - \"count\"\n",
    "data.groupby('author')['score'].count().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#author which has highest mean score - \"mean\"\n",
    "data.groupby('author')['score'].mean().reset_index().sort_values('score', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e830a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#author with its \"mean score\" and \"count of score\"\n",
    "author_mean_count = pd.DataFrame(data.groupby('author')['score'].mean())\n",
    "author_mean_count['score_counts'] = pd.DataFrame(data.groupby('author')['score'].count()) \n",
    "author_mean_count.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599b07f",
   "metadata": {},
   "source": [
    "**Observation** - Although some of the authors have score as 10, the score_count of the author is 1 hence the mean of score will be 10, which is less significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams['patch.force_edgecolor'] = True\n",
    "author_mean_count['score'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d53f3e",
   "metadata": {},
   "source": [
    "#### C. Select the data with products having more than 50 ratings and users who have given more than 50 ratings. Report the shape of the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f403725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the data with products having more than 50 ratings\n",
    "min_phone_ratings = 50\n",
    "filter_products = data['product'].value_counts() > min_phone_ratings\n",
    "filter_products = filter_products[filter_products].index.tolist()\n",
    "print('Number of products with >50 rating: ', len(filter_products))\n",
    "\n",
    "#users who have given more than 50 ratings\n",
    "min_user_ratings = 50\n",
    "filter_users = data['author'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "print('Number of authors who have given >50 rating: ', len(filter_users))\n",
    "\n",
    "print()\n",
    "\n",
    "data_new = data[(data['product'].isin(filter_products)) & (data['author'].isin(filter_users))]\n",
    "\n",
    "print('Shape of the dataframe after selecting the data with products having more than 50 ratings and users who have given more than 50 ratings', data_new.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "data_new.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f68d7c",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ddb8a",
   "metadata": {},
   "source": [
    "### 3. Build a popularity based model and recommend top 5 mobile phones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product with its mean score.\n",
    "ratings_mean_count = pd.DataFrame(data.groupby('product')['score'].mean())\n",
    "\n",
    "# product with its score count\n",
    "ratings_mean_count['rating_counts'] = pd.DataFrame(data.groupby('product')['score'].count())  \n",
    "\n",
    "#top 5 mobile phones.\n",
    "ratings_mean_count.sort_values(by=['score','rating_counts'], ascending=[False,False]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ef4db",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e52795",
   "metadata": {},
   "source": [
    "### 4. Build a collaborative filtering model using SVD. You can use SVD from surprise or build it from scratch(Note: Incase you’re building it from scratch you can limit your data points to 5000 samples if you face memory issues). Build a collaborative filtering model using kNNWithMeans from surprise. You can try both user-based and item-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arranging columns in the order of user id,item id and score\n",
    "columns_titles = ['author','product','score']\n",
    "data_model = data.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2522fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 5000 data samples. Use random state=612\n",
    "data_model = data_model.sample(n=5000, random_state=612)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e586c6e",
   "metadata": {},
   "source": [
    "#### a) Build a collaborative filtering model using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5818dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns for SVD and prepare train and testsets\n",
    "data_svd = Dataset.load_from_df(data[['author','product','score']], Reader(rating_scale=(1, 10)))\n",
    "trainset_svd, testset_svd = train_test_split(data_svd, test_size=.25,random_state=612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict using svd\n",
    "def svd_func(train, test):\n",
    "    algo_svm = SVD(random_state=612)\n",
    "    algo_svm.fit(train)\n",
    "    test_pred_svd = algo_svm.test(test)\n",
    "    return test_pred_svd, algo_svm\n",
    "\n",
    "test_pred_svd, algo_svm = svd_func(trainset_svd, testset_svd)\n",
    "print('First few prediction values: \\n',test_pred_svd[0:2])\n",
    "print('\\nRMSE value(test-set): ',round(accuracy.rmse(test_pred_svd),2),'\\n') # compute RMSE\n",
    "svd_rmse = round(accuracy.rmse(test_pred_svd),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fda28",
   "metadata": {},
   "source": [
    "#### b) Build a collaborative filtering model using KNN With Means from surprise using user-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data_Knn_user = Dataset.load_from_df(data_model,reader = reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_knn_user = data_Knn_user.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31746880",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_u = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo_u.fit(trainset_knn_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbce0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_knn_user = trainset_knn_user.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21891c2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_pred_knn_user = algo_u.test(testset_knn_user)\n",
    "test_pred_knn_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c85eca",
   "metadata": {},
   "source": [
    "#### c) Build a collaborative filtering model using KNN With Means from surprise using Item-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data_Knn_item = Dataset.load_from_df(data_model,reader = reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228250a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_knn_item = data_Knn_item.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae45f1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_i = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo_i.fit(trainset_knn_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528723cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_knn_item = trainset_knn_item.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a760722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_knn_item = algo_i.test(testset_knn_item)\n",
    "test_pred_knn_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb013f",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d009dbf",
   "metadata": {},
   "source": [
    "### 5. Evaluate the collaborative model. Print RMSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5e821",
   "metadata": {},
   "source": [
    "#### a) SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016db5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVD Model : Test data\")\n",
    "accuracy.rmse(test_pred_svd, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dac846",
   "metadata": {},
   "source": [
    "#### b) User-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79d5d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred_knn_user, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7647a8",
   "metadata": {},
   "source": [
    "#### c) Item-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f25d3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Item-based Model :Test Set\")\n",
    "accuracy.rmse(test_pred_knn_item, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58e6e",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d715a",
   "metadata": {},
   "source": [
    "### 6. Predict score (average rating) for test users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e9db4",
   "metadata": {},
   "source": [
    "#### a) SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_pred = pd.DataFrame(test_pred_svd, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "print('average prediction for test users for SVD Model: ',svd_pred['est'].mean())\n",
    "print('average rating by test users for SVD Model: ',svd_pred['rui'].mean())\n",
    "print('average prediction error for test users for SVD Model: ',(svd_pred['rui']-svd_pred['est']).abs().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dd3af",
   "metadata": {},
   "source": [
    "#### b) User-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94831cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_u_pred=pd.DataFrame(test_pred_knn_user, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "print('average prediction for test users for User-based Model: ',knn_u_pred['est'].mean())\n",
    "print('average rating by test users for User-based Model: ',knn_u_pred['rui'].mean())\n",
    "print('average prediction error for test users for User-based Model: ',(knn_u_pred['rui']-knn_u_pred['est']).abs().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed2345",
   "metadata": {},
   "source": [
    "#### c) Item-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_i_pred=pd.DataFrame(test_pred_knn_item, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "print('average prediction for test users for Item-based Model: ',knn_i_pred['est'].mean())\n",
    "print('average rating by test users for Item-based Model: ',knn_i_pred['rui'].mean())\n",
    "print('average prediction error for test users for Item-based Model: ',(knn_i_pred['rui']-knn_i_pred['est']).abs().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b54c0f",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a2f6d",
   "metadata": {},
   "source": [
    "### 7. Report your findings and inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356497a",
   "metadata": {},
   "source": [
    "**Top 5 most rated products are** -\n",
    "1. Lenovo Vibe K4 Note (White,16GB)\n",
    "2. Lenovo Vibe K4 Note (Black, 16GB)  \n",
    "3. OnePlus 3 (Graphite, 64 GB)            \n",
    "4. OnePlus 3 (Soft Gold, 64 GB)         \n",
    "5. Huawei P8lite zwart / 16 GB           \n",
    "\n",
    "**Authors with most number of review** -\n",
    "- Although we cleaned the data for \"nan\" values, \"Anonymous\" and \"unknown\". We see there are author names in different languages which also means - \"Unknown\".(not cleaned)\n",
    "- Overall data is highly skewed towards 'Amazon customers' from different countries.\n",
    "- \"Amazon\" has the most number of reviews. Although correct 'user' names from 'Amazon' should have used.\n",
    "\n",
    "**Products having more than 50 ratings and Users who have given more than 50 ratings.**\n",
    "1. Denni - Apple iPhone 6 Space Grau 128GB SIM-Free Smart...\n",
    "2. Amazon Kunde - Samsung Galaxy S7 Smartphone (5,1 Zoll (12,9 c...\n",
    "3. Amazon Customer - Apple iPhone 3GS 16GB (White) - AT&T\n",
    "4. Amazon Customer - OnePlus 3T (Gunmetal, 6GB RAM + 64GB memory)\n",
    "5. Amazon Customer - Lenovo Vibe K5 (Silver, 16GB)\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "**SVM Model**\n",
    "\n",
    "SVD Model : Test data\n",
    "RMSE: 2.5267\n",
    "\n",
    "- average prediction for test users:  8.017424546767772\n",
    "- average rating by test users:  8.001028\n",
    "- average prediction error for test users:  1.9522398766493418\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "**User-based Model**\n",
    "\n",
    "User-based Model : Test Set\n",
    "RMSE: 2.5424\n",
    "\n",
    "- average prediction for test users:  8.06401472612044\n",
    "- average rating by test users:  8.016599998590907\n",
    "- average prediction error for test users:  1.9390806236844527\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "**Item-based Model**\n",
    "\n",
    "Item-based Model :Test Set\n",
    "RMSE: 2.5288\n",
    "\n",
    "- average prediction for test users:  7.980277888766065\n",
    "- average rating by test users:  8.016599998590907\n",
    "- average prediction error for test users:  1.9407905319252805\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "**Conclusion** - \n",
    "- RMSE Error is approximately same for all 3 models but our model perfoms well in SVM Model.\n",
    "- average prediction error for test users - is less in User-based Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f491195",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35423e9c",
   "metadata": {},
   "source": [
    "### 8. Try and recommend top 5 products for test users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=5):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1babaec",
   "metadata": {},
   "source": [
    "#### a) SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f247d6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_5_SVD = get_top_n(test_pred_svd, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 5 recommendations:SVD \\n')\n",
    "for key,value in top_5_SVD.items(): print(key,'-> ',value,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343e97e",
   "metadata": {},
   "source": [
    "#### b) User-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d27087",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_5_knn_u = get_top_n(test_pred_knn_user,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 5 recommendations:User \\n')\n",
    "for key,value in top_5_knn_u.items(): print(key,'-> ',value,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600134bd",
   "metadata": {},
   "source": [
    "#### c) Item-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def514e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_5_knn_i = get_top_n(test_pred_knn_item ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 5 recommendations:Item \\n')\n",
    "for key,value in top_5_knn_i.items(): print(key,'-> ',value,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e3217",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cf540",
   "metadata": {},
   "source": [
    "### 9. Try other techniques (Example: cross validation) to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d58d95",
   "metadata": {},
   "source": [
    "#### a) SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cv = cross_validate(algo_svm, data_svd, measures=['RMSE'], cv=5, verbose=False)\n",
    "print('\\n Mean of svm_cv score:', round(svm_cv['test_rmse'].mean(),2),'\\n')\n",
    "svm_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85841f83",
   "metadata": {},
   "source": [
    "#### b) User-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c352fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_u_cv = cross_validate(algo_u, data_Knn_user, measures=['RMSE'], cv=5, verbose=False)\n",
    "print('\\n Mean of knn_u_cv score:', round(knn_u_cv['test_rmse'].mean(),2),'\\n')\n",
    "knn_u_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70969e4",
   "metadata": {},
   "source": [
    "#### c) Item-based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ed798",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_i_cv = cross_validate(algo_i, data_Knn_item, measures=['RMSE'], cv=5, verbose=False)\n",
    "print('\\n Mean of knn_i_cv score:', round(knn_i_cv['test_rmse'].mean(),2),'\\n')\n",
    "knn_i_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb8ff7",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28dac93",
   "metadata": {},
   "source": [
    "**Conclusion** - After applying cross validation technique -\n",
    "- Mean of svm_cv score: 2.52 (which is same as our SVM Model)\n",
    "- Mean of knn_u_cv score: 2.63 (the value has increased from 2.54 to 2.63)\n",
    "- Mean of knn_i_cv score: 2.65 (the value has increased from 2.52 to 2.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ab09a",
   "metadata": {},
   "source": [
    "### 10. In what business scenario you should use popularity based Recommendation Systems ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821e512",
   "metadata": {},
   "source": [
    "Popularity based Recommendation Systems is a type of recommendation system which works on the **principle of popularity and or trend** and directly recommend to the users.\n",
    "\n",
    "\n",
    "This can be used in a scenario where we do not have user preference or for new users i.e, It does not suffer from cold start problems which means **on day 1 of the business also it can recommend products on various different filters and does not require user's historical data.**\n",
    "\n",
    "\n",
    "For example, if a product is often purchased by most people then the system will get to know that that product is most popular so for every new user who just signed it, the system will recommend that product to that user also and **chances will be high that the new user will also purchase that**. \n",
    "\n",
    "\n",
    "Examples - \n",
    "- **YouTube**: Trending videos. \n",
    "- **Google News**: News filtered by trending and most popular news.\n",
    "- **Twitter** - Trending #.\n",
    "-  **Music App** - To discover trending music from different catalogs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236bc68",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77232e",
   "metadata": {},
   "source": [
    "### 11. In what business scenario you should use CF based Recommendation Systems ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee583782",
   "metadata": {},
   "source": [
    "Collaborative Filtering is considered to be one of the smart recommender systems that work on the **similarity between different users and also items** that are widely used as an e-commerce website and also online movie websites. It checks about the **taste of similar users** and does recommendations. It is a **personalised recommender system**, recommendations are made based on the past behaviour of the user.\n",
    "\n",
    "\n",
    "It is suited for a set of different types of items, for example, a supermarket’s inventory where items of various categories can be added. In a set of similar items such as that of a bookstore, though, known features like writers and genres can be useful and might benefit from content-based or hybrid approaches.\n",
    "\n",
    "\n",
    "Collaborative filtering can help recommenders to not overspecialize in a user’s profile and recommend items that are completely different from what they have seen before. If you want your recommender to **not suggest a pair of sneakers to someone who just bought another similar pair of sneakers, then try to add collaborative filtering to your recommender spell**.\n",
    "\n",
    "\n",
    "Examples- Most websites like **Amazon, YouTube, and Netflix** use collaborative filtering as a part of their sophisticated recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df47ce",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf540384",
   "metadata": {},
   "source": [
    "### 12. What other possible methods can you think of which can further improve the recommendation for different users ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed977fe7",
   "metadata": {},
   "source": [
    "Other possible methods like hybrid recommendation system can be considered which is the combination of the content and collaborative filtering method. Combining collaborative and content-based filtering together may help in overcoming the shortcoming we are facing at using them separately and also can be more effective in some cases. \n",
    "\n",
    "Some of the approaches are -\n",
    "\n",
    "**a) Weighted recommendation system** - The weighted recommendation system will take the outputs from each of the models and combine the result in static weightings, which the weight does not change across the train and test set.\n",
    "\n",
    "For example, we can combine a content-based model and a item-item collaborative filtering model, and each takes a weight of 50% toward the final prediction.\n",
    "\n",
    "**b) Switching hybrid recommendation system** - This selects a single recommendation system based on the situation. The model is used to be built for the item-level sensitive dataset, we should set the recommender selector criteria based on the user profile or other features.The switching hybrid approach introduces an additional layer upon the recommendation model, which select the appropriate model to use.\n",
    "\n",
    "**c) Mixed hybrid recommendation system** - This approach first takes the user profile and features to generate different set of candidate datasets and inputs this to the recommendation model accordingly, and combine the prediction to produce the result recommendation.It is able to make large number of recommendations simultaneously, and fit the partial dataset to the appropriate model in order to have better performance.\n",
    "\n",
    "**d) Feature Combination** - Here we can inject features of a collaborative recommendation model into an content-based recommendation model. The hybrid model is capable to consider the collaborative data from the sub system with relying on one model exclusively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b01e8",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
